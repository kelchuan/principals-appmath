{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr align=left><td><img align=left src=\"./images/CC-BY.png\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license. (c) Marc Spiegelman</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Total Least Squares\n",
    "\n",
    "**GOAL:** Demonstrate the use of the SVD to calculate total least squares regression and compare it to the classical least squares problem that assumes only errors in y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random data: \n",
    "\n",
    "We start by constructing a random data set that approximates a straight line but has random errors in both x and y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# npoints uniformly randomly distributed points in the interval [0,3]\n",
    "npnts =50\n",
    "x = np.random.uniform(0.,3.,npnts)\n",
    "\n",
    "# set y = mx + b plus random noise of size err\n",
    "slope = 2.\n",
    "intercept = 1.\n",
    "err = .5\n",
    "\n",
    "y = slope*x + intercept \n",
    "y += np.random.normal(loc=y,scale=err)\n",
    "\n",
    "# add some random noise to x variable as well\n",
    "x += np.random.normal(loc=x,scale=err)\n",
    "\n",
    "# And plot out the data\n",
    "plt.figure()\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Data')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical Least Squares:  \n",
    "\n",
    "We first calculate the best fit straight line assuming all the error is in the y variable using the a QR decomposition of the Vandermonde matrix [ 1 x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vandermonde matrix\n",
    "A = np.array([ np.ones(x.shape), x]).T\n",
    "\n",
    "# solve  Ac = y using the QR decomposition via scipy\n",
    "c_ls,res,rank,s = la.lstsq(A,y)\n",
    "print 'Best fit Linear Least Squares:'\n",
    "print '    slope={}'.format(c_ls[1])\n",
    "print '    intercept={}'.format(c_ls[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Least Squares:  \n",
    "\n",
    "We now use the SVD to decompose the demeaned data matrix into its principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data matrix\n",
    "X = np.array([ x , y]).T\n",
    "X_mean = np.mean(X,0)\n",
    "print  'Mean of data matrix=',X_mean\n",
    "\n",
    "# de-mean the data matrix\n",
    "X -= X_mean\n",
    "\n",
    "# now calculate the SVD of the de-meaned data matrix\n",
    "U,S,VT = la.svd(X,full_matrices=False)\n",
    "V = VT.T\n",
    "print 'Singular values=', S\n",
    "print 'First Right singular vector V=', V[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot and compare the two solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dummy variables \n",
    "t_ls = np.linspace(0,x.max())\n",
    "t_svd =  2*(t_ls - np.mean(t_ls))\n",
    "\n",
    "# make figure\n",
    "plt.figure()\n",
    "# plot data\n",
    "plt.scatter(x,y)\n",
    "# plot the least squares solution\n",
    "plt.plot(t_ls,c_ls[0]+t_ls*c_ls[1],'r-',label='Least Squares')\n",
    "\n",
    "# plot the total least Squares solution\n",
    "# plot the mean\n",
    "plt.plot(X_mean[0],X_mean[1],'go')\n",
    "# calculate a line through the mean with the first principal component as a basis\n",
    "L_tls = X_mean + np.outer(t_svd,V[:,0])\n",
    "plt.plot(L_tls[:,0],L_tls[:,1],'c-',label='Total Least Squares')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Comparison Least Squares vs Total Least Squares')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
